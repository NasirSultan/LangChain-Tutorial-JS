
# LangChain AI Agent with Wikipedia Tool

## Overview

This project demonstrates how to build a conversational AI agent using [LangChain](https://js.langchain.com/) with the [Mistral AI](https://mistral.ai/) large language model. It integrates a custom Wikipedia tool that allows the agent to answer complex, knowledge-based questions with accurate information fetched directly from Wikipedia.

## Features

* Uses the `mistral-large-latest` model from Mistral AI
* Employs the powerful LangChain agent architecture with `structured-chat-zero-shot-react-description` agent type
* Integrates a custom Wikipedia tool to handle real-time searches
* Accepts natural language questions and produces detailed, accurate answers

## Technologies

* LangChain (JavaScript)
* Mistral AI via `@langchain/mistralai`
* Custom Tool Integration
* dotenv for environment variable management

## How It Works

1. Initializes the Mistral AI model with custom temperature and API key.
2. Sets up a structured chat agent using LangChain’s agent executor.
3. Loads the custom WikipediaTool to fetch information directly from Wikipedia.
4. Passes a natural language question (e.g., “Who was Nikola Tesla and what did he invent?”) to the agent.
5. Outputs a rich, informative answer using both LLM reasoning and external tool knowledge.

## Setup Instructions

1. Clone the repository.
2. Install dependencies with your preferred package manager.
3. Create a `.env` file and add your `MISTRAL_API_KEY`.
4. Run the project with Node.js (preferably v18+).

## Example Input

Who was Nikola Tesla and what did he invent?

## Output

A complete response generated by the Mistral model, including real-time data pulled from Wikipedia.


